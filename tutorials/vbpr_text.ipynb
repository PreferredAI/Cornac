{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Cornac Authors. All rights reserved.*\n",
    "\n",
    "*Licensed under the Apache 2.0 License.*\n",
    "\n",
    "# Visual Bayesian Personalizer Ranking with Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/PreferredAI/cornac/blob/master/tutorials/vbpr_text.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/PreferredAI/cornac/blob/master/tutorials/vbpr_text.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We would like to use [Visual Bayesian Personalizer Ranking (VBPR)](https://arxiv.org/pdf/1510.01784.pdf), it makes use of pre-trained visual features extracted from CNN. However, our data of interest [MovieLens dataset](https://grouplens.org/datasets/movielens/) does not come with visual information, but instead it contains text movie plots. In this tutorial, we will employ Conac's modality infrastructures to easily utilize VBPR to leverage item text content.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Cornac\n",
    "!pip3 install numpy cornac\n",
    "# install PyTorch for VBPR model\n",
    "!pip3 install torch==1.0.0\n",
    "\n",
    "import cornac\n",
    "from cornac.data import Reader\n",
    "from cornac.datasets import movielens\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data import TextModality, ImageModality\n",
    "from cornac.data.text import BaseTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Here we use the MovieLens 100K dataset which is already accessible from Cornac. Hence, we can simply load movie plots and the rating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots, movie_ids = movielens.load_plot()\n",
    "\n",
    "# movies without plots are filtered out by `cornac.data.Reader`\n",
    "ml_100k = movielens.load_100k(reader=Reader(item_set=movie_ids)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross modality\n",
    "\n",
    "To get representations from text data, we build a `TextModality` using text corpus with coressponding ids as the input. We also need to supply a `Tokenizer` for text splitting, in this case the tokens in text plots are seperated by `\\tab` character. We limit the maximum size of vocabulary to 5000, which also means the size of representations (e.g., bag-of-words vectors) can not go beyond that limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_text_modality = TextModality(corpus=plots, ids=movie_ids, \n",
    "                                  tokenizer=BaseTokenizer(sep='\\t', stop_words='english'),\n",
    "                                  max_vocab=5000, max_doc_freq=0.5).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the `TextModality`, we can access text representations through provided APIs and attributes of the object. In this case, we take the word-count matrix as item representations then use it as input to construct an `ImageModality`. In other words, item visual representations will be substituted by bag-of-words representations which are used by `VBPR` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = item_text_modality.count_matrix.A\n",
    "item_image_modality = ImageModality(features=features, ids=movie_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Cornac, image recommendation models always work with `ImageModality`, similarly for other modalities. That design makes it consistent with models' original assumptions, thus it's easy to integrate models into the library without any confusion of which modality to use.\n",
    "\n",
    "## Experiment\n",
    "\n",
    "We employ `RatioSplit` evaluation method to split the rating data. The `item_image_modality` is also supplied here for later usage of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_split = RatioSplit(data=ml_100k, test_size=0.9,\n",
    "                         item_image=item_image_modality,\n",
    "                         exclude_unknowns=True, \n",
    "                         verbose=True, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VBPR model is supported inside Cornac. Note that the implementation of VBPR uses [PyTorch](https://pytorch.org/), thus we need to install that dependency in order to run the model (done at the beginning). List of implemented models with their additional dependencies is carefully documented [here](https://github.com/PreferredAI/cornac#models).\n",
    "We also use [BPR](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf) model as a baseline to see the effectiveness of the text auxiliary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbpr = cornac.models.VBPR(k=10, k2=10, n_epochs=20, batch_size=20, learning_rate=0.001,\n",
    "                          lambda_w=1.0, lambda_b=0.0, lambda_e=100.0, use_gpu=True, seed=123)\n",
    "\n",
    "bpr = cornac.models.BPR(k=20, max_iter=100, learning_rate=0.001, lambda_reg=0.001, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = cornac.metrics.AUC()\n",
    "rec_50 = cornac.metrics.Recall(k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cornac.Experiment(eval_method=ratio_split,\n",
    "                  models=[bpr, vbpr],\n",
    "                  metrics=[auc, rec_50]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results after running the experiment:\n",
    "\n",
    "<pre>\n",
    "     |    AUC | Recall@50 | Train (s) | Test (s)\n",
    "---- + ------ + --------- + --------- + --------\n",
    "BPR  | 0.7355 |    0.2297 |    1.3699 |  12.9997\n",
    "VBPR | 0.7669 |    0.2499 |   61.1777 |  17.2591\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
