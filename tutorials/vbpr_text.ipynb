{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) Cornac Authors. All rights reserved.*\n",
    "\n",
    "*Licensed under the Apache 2.0 License.*\n",
    "\n",
    "#Visual Bayesian Personalizer Ranking (VBPR) with Text Data\n",
    "\n",
    "<br><br>\n",
    "In this tutorial, we will employ a recommendation algorithm, designed to leverage item images, to work with item text content.\n",
    "The model of interest here is [VBPR](https://arxiv.org/abs/1510.01784) that makes use of visual features extracted from item images using pre-trained CNN deep networks.\n",
    "\n",
    "![](images/VBPR.png)\n",
    "\n",
    "<br>\n",
    "However, what if our data doesn't come with item images but text, for example, we are working with [MovieLens dataset](https://grouplens.org/datasets/movielens/) that contains text plot of the movies. At the same time, we also want to work with VBPR model which is not originally designed to work with text data. Thus, Cornac provides simple mechanisms to cross between modalities, in which here we focus on crossing from text to image to utilize image models for text-available datasets.\n",
    "\n",
    "To quickly give an overview of the process, we are going to go through following steps:\n",
    "1. Use `TextModality` to build representations (e.g., bag-of-words, tf-idf) from raw text data.\n",
    "2. Construct `ImageModality`, which will be used by `VBPR` model, from textual representations.\n",
    "3. Split data using provided `RatioSplit` evaluation method.\n",
    "4. Define models and metrics used to evaluate models' performance.\n",
    "5. Test the models by running an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cornac\n",
    "from cornac.data import Reader\n",
    "from cornac.datasets import movielens\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.data import TextModality, ImageModality\n",
    "from cornac.data.text import BaseTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use MovieLens 100K dataset as already provided inside Cornac library. We load movie plots with their corresponding ids, then load the rating data filtered the movies that don't come with plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load movie plots from built-in movielens datasets\n",
    "plots, movie_ids = movielens.load_plot()\n",
    "\n",
    "# load rating data of MovieLens 100K\n",
    "# movies without plot are filtered out using `cornac.data.Reader`\n",
    "ml_100k = movielens.load_100k(reader=Reader(item_set=movie_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get representations from text data, we build a `TextModality` using text corpus with coressponding ids as the input. We also need to supply a `Tokenizer` for text splitting, in this case the tokens in text plots are seperated by `\\tab` character. We limit the maximum size of vocabulary to 5000, which also means the size of representations (e.g., bag-of-words vectors) can not go beyond that limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a tokenizer to split text into tokens using \\tab character as text seperator\n",
    "# we also tell the tokenizer to ignore English stopwords\n",
    "tokenizer = BaseTokenizer(sep='\\t', stop_words='english')\n",
    "\n",
    "# now we can build a TextModality given movie plots and their corresponding ids\n",
    "item_text_modality = TextModality(corpus=plots, ids=movie_ids, \n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_vocab=5000, max_doc_freq=0.5).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the `TextModality`, we can access text representations through provided APIs and attributes of the object. In this case, we take the word-count matrix as item representations then use it as input to construct an `ImageModality`. In other words, item visual representations will be substituted by bag-of-words representations which are used by `VBPR` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word-count matrix from TextModality will be used as input features to construct an ImageModality\n",
    "# the `count_matrix` is originally stored in sparse format, we need to turn it into dense format\n",
    "features = item_text_modality.count_matrix.A\n",
    "\n",
    "# construct an ImageModality given features and movie ids as the input\n",
    "item_image_modality = ImageModality(features=features, ids=movie_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Cornac, image recommendation models always work with `ImageModality`, similarly for other modalities. That design makes it easier to integrate models into the library without confusion of data input, as well as makes it consistent with models' original assumptions.\n",
    "\n",
    "We employ `RatioSplit` evaluation method to split the rating data. The `item_image_modality` is also supplied here for later usage of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_split = RatioSplit(data=ml_100k, test_size=0.2,\n",
    "                         item_image=item_image_modality,\n",
    "                         exclude_unknowns=True, \n",
    "                         verbose=True, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VBPR model is supported inside Cornac. Note that the VBPR implementation uses [PyTorch](https://pytorch.org/), thus we need to install that dependency in order to run the model. List of implemented models with their additional dependencies is carefully documented [here](https://github.com/PreferredAI/cornac#models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VBPR model with the model hyper-parameters\n",
    "vbpr = cornac.models.VBPR(k=10, k2=20, n_epochs=30, batch_size=100, learning_rate=0.005,\n",
    "                          lambda_w=1, lambda_b=0.01, lambda_e=0.0, use_gpu=True, seed=123)\n",
    "\n",
    "# BPR is used as a baseline\n",
    "bpr = cornac.models.BPR(k=30, max_iter=30, learning_rate=0.01, lambda_reg=0.001, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use `AUC` and `Recall@50` to measure models' performance\n",
    "auc = cornac.metrics.AUC()\n",
    "rec_50 = cornac.metrics.Recall(k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment to test the models\n",
    "cornac.Experiment(eval_method=ratio_split,\n",
    "                  models=[bpr, vbpr],\n",
    "                  metrics=[auc, rec_50]).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results after running the experiment:\n",
    "\n",
    "<pre>\n",
    "     |    AUC | Recall@50 | Train (s) | Test (s)\n",
    "---- + ------ + --------- + --------- + --------\n",
    "BPR  | 0.8204 |    0.2236 |    0.2269 |   0.5853\n",
    "VBPR | 0.8587 |    0.3012 |  199.3364 |   0.8134\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
